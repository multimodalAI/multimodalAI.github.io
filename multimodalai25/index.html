<!doctype html><html lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1"><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=generator content="Wowchemy 5.7.0 for Hugo"><link rel=stylesheet href=/css/vendor-bundle.min.16f785cdb553c8c4431db6775122af35.css media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/academicons@1.9.2/css/academicons.min.css integrity="sha512-KlJCpRsLf+KKu2VQa5vmRuClRFjxc5lXO03ixZt82HZUk41+1I0bD8KBSA0fY290ayMfWYI9udIqeOWSu1/uZg==" crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.css integrity crossorigin=anonymous media=print onload='this.media="all"'><link rel=stylesheet href=/css/wowchemy.b9231f75dcc97a371ce6141b4d2aadaf.css><link rel=stylesheet href=/css/libs/chroma/github-light.min.css title=hl-light media=print onload='this.media="all"'><link rel=stylesheet href=/css/libs/chroma/dracula.min.css title=hl-dark media=print onload='this.media="all"' disabled><script async src="https://www.googletagmanager.com/gtag/js?id=G-5K2K2GHWHQ"></script><script>window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}function trackOutboundLink(e,t){gtag("event","click",{event_category:"outbound",event_label:e,transport_type:"beacon",event_callback:function(){t!=="_blank"&&(document.location=e)}}),console.debug("Outbound link clicked: "+e)}function onClickCallback(e){if(e.target.tagName!=="A"||e.target.host===window.location.host)return;trackOutboundLink(e.target,e.target.getAttribute("target"))}gtag("js",new Date),gtag("config","G-5K2K2GHWHQ",{}),gtag("set",{cookie_flags:"SameSite=None;Secure"}),document.addEventListener("click",onClickCallback,!1)</script><meta name=author content="Haiping Lu"><meta name=description content><link rel=alternate hreflang=en-us href=https://multimodalAI.github.io/multimodalai25/><link rel=canonical href=https://multimodalAI.github.io/multimodalai25/><link rel=manifest href=/manifest.webmanifest><link rel=icon type=image/png href=/media/icon_hu25caa61f2e6d310cd2b668efa4781043_104298_32x32_fill_lanczos_center_3.png><link rel=apple-touch-icon type=image/png href=/media/icon_hu25caa61f2e6d310cd2b668efa4781043_104298_180x180_fill_lanczos_center_3.png><meta name=theme-color content="#1565c0"><meta property="twitter:card" content="summary"><meta property="twitter:site" content="@MultimodalAI_UK"><meta property="twitter:creator" content="@MultimodalAI_UK"><meta property="twitter:image" content="https://multimodalAI.github.io/media/icon_hu25caa61f2e6d310cd2b668efa4781043_104298_512x512_fill_lanczos_center_3.png"><meta property="og:site_name" content="UK Open Multimodal AI Network"><meta property="og:url" content="https://multimodalAI.github.io/multimodalai25/"><meta property="og:title" content="UK Open Multimodal AI Network"><meta property="og:description" content><meta property="og:image" content="https://multimodalAI.github.io/media/icon_hu25caa61f2e6d310cd2b668efa4781043_104298_512x512_fill_lanczos_center_3.png"><meta property="og:locale" content="en-us"><title>UK Open Multimodal AI Network</title></head><body id=top data-spy=scroll data-offset=70 data-target=#TableOfContents class=page-wrapper data-wc-page-id=9e5fcd79eb87240497216bb6b07770c5><script src=/js/wowchemy-init.min.ec9d49ca50e4b80bdb08f0417a28ed84.js></script><aside class=search-modal id=search><div class=container><section class=search-header><div class="row no-gutters justify-content-between mb-3"><div class=col-6><h1>Search</h1></div><div class="col-6 col-search-close"><a class=js-search href=# aria-label=Close><i class="fas fa-times-circle text-muted" aria-hidden=true></i></a></div></div><div id=search-box><input name=q id=search-query placeholder=Search... autocapitalize=off autocomplete=off autocorrect=off spellcheck=false type=search class=form-control aria-label=Search...></div></section><section class=section-search-results><div id=search-hits></div></section></div></aside><div class="page-header header--fixed"><header><nav class="navbar navbar-expand-lg navbar-light compensate-for-scrollbar" id=navbar-main><div class=container-xl><div class="d-none d-lg-inline-flex"><a class=navbar-brand href=/>UK Open Multimodal AI Network</a></div><button type=button class=navbar-toggler data-toggle=collapse data-target=#navbar-content aria-controls=navbar-content aria-expanded=false aria-label="Toggle navigation">
<span><i class="fas fa-bars"></i></span></button><div class="navbar-brand-mobile-wrapper d-inline-flex d-lg-none"><a class=navbar-brand href=/>UK Open Multimodal AI Network</a></div><div class="navbar-collapse main-menu-item collapse justify-content-end" id=navbar-content><ul class="navbar-nav d-md-inline-flex"><li class=nav-item><a class=nav-link href=/omaib><span>Funding Call</span></a></li><li class=nav-item><a class=nav-link href=/multimodalai25 data-target=[]><span>MultimodalAI'25</span></a></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>About</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/#ukomain><span>UKOMAIN</span></a>
<a class=dropdown-item href=/#team><span>Team</span></a>
<a class=dropdown-item href=/#contact><span>Contact</span></a></div></li><li class="nav-item dropdown"><a href=# class="nav-link dropdown-toggle" data-toggle=dropdown aria-haspopup=true><span>Past Events</span><span class=caret></span></a><div class=dropdown-menu><a class=dropdown-item href=/embc25workshop><span>EMBC'25Workshop</span></a>
<a class=dropdown-item href=/multimodalai24><span>MultimodalAI'24</span></a>
<a class=dropdown-item href=/multimodalai-forum24><span>MultimodalAIForum'24</span></a>
<a class=dropdown-item href=/multimodalai-sprint23><span>MultimodalAISprint'23</span></a>
<a class=dropdown-item href=/multimodalai23><span>MultimodalAI'23</span></a></div></li><li class=nav-item><a class=nav-link href=/code-of-conduct><span>Code of Conduct</span></a></li></ul></div><ul class="nav-icons navbar-nav flex-row ml-auto d-flex pl-md-2"><li class=nav-item><a class="nav-link js-search" href=# aria-label=Search><i class="fas fa-search" aria-hidden=true></i></a></li><li class="nav-item dropdown theme-dropdown"><a href=# class=nav-link data-toggle=dropdown aria-haspopup=true aria-label="Display preferences"><i class="fas fa-moon" aria-hidden=true></i></a><div class=dropdown-menu><a href=# class="dropdown-item js-set-theme-light"><span>Light</span>
</a><a href=# class="dropdown-item js-set-theme-dark"><span>Dark</span>
</a><a href=# class="dropdown-item js-set-theme-auto"><span>Automatic</span></a></div></li></ul></div></nav></header></div><div class=page-body><span class="js-widget-page d-none"></span><section id=about class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Third Workshop on Multimodal AI</h1><p class=mt-1>16–17 September 2025, London, UK</p></div><div class=col-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:2px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div><p><strong>Latest news</strong></p><ul><li>Preliminary programme released - <a href=/multimodalai25/#programme>View more</a></li><li>Mini-Hackathon announced - <a href=/multimodalai25/hackathon/>View more</a> (open to all workshop attendees)</li><li>Photo competition - <a href=/multimodalai25/photo-competition/>Call for entries</a> (submission deadline is <strong>16 September 2025</strong>)</li><li>Accepted abstracts - <a href=/multimodalai25/accepted-abstracts/>View all abstracts</a></li><li>Registration closed on 7 September 2025 at 11:00 PM</li><li>Sponsorship opportunities - <a href=/call-for-sponsorship/>View more</a></li><li>Keynote speakers confirmed - <a href=#speaker>View more</a></li></ul><hr><p>You are warmly invited to join the Third Workshop on Multimodal AI (MultimodalAI'25), taking place on <strong>16 and 17 September 2025</strong> at the <strong>Barbican Centre</strong>, <strong>London</strong>, <strong>EC2Y 8DS</strong>. This workshop will be an in-person-only event, preceded by a <strong>mini-hackathon</strong> on <strong>15 September</strong> at the <strong>Torrington Place (1-19)</strong>, <strong>London</strong>, <strong>WC1E 7HB</strong>.</p><p>Multimodal AI integrates diverse types of data, such as text, images, and sound, swiftly revolutionising how we interact with technology and information. Following two successful workshops, MultimodalAI’25 will gather researchers and practitioners from AI, data science, and various scientific and applied domains. The workshop aims to discuss challenges, share innovative solutions, explore future collaborations, and further build our vibrant multimodal AI community.</p><p>Hosted by the UK Open Multimodal AI Network (UKOMAIN)—a £1.8 million EPSRC Network Plus project—the event features keynote presentations from leading experts, community pitches, talks and posters, engaging panel discussions, a photo competition, and valuable funding and policy briefings. Prizes will recognise outstanding pitches, talks, posters, and photos. Additionally, we offer travel bursaries and volunteering opportunities to support participants.</p><p>Join this interdisciplinary gathering to connect, collaborate, and drive forward multimodal AI research and development. For further details, follow us at <a href=https://www.linkedin.com/company/ukomain target=_blank rel=noopener>https://www.linkedin.com/company/ukomain</a>.</p></div></div></div></section><section id=speaker class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Keynote Speakers</h1></div><div class=col-md-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/ampea-karikari-boateng/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/ampea-karikari-boateng/avatar_hu141cde6a18d77107048fa41c735dc157_37994_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/ampea-karikari-boateng/>Ampea Karikari-Boateng</a></h2><h3>Principal R&amp;D Engineer in Wind Turbine Architecture at Offshore Renewable Energy Catapult</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/ampea-karikari-boateng-8b684a27/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://ore.catapult.org.uk/ target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/anna-barnes/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/anna-barnes/avatar_hudfa710ab06fd44a85f382a840b39766b_39328_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/anna-barnes/>Anna Barnes</a></h2><h3>Advisory Board Member of the UK Open Multimodal AI Network, Director of the King&rsquo;s Technology Evaluation Centre at King&rsquo;s College London, and President of Institute of Physics and Engineering in Medicine</h3><ul class=network-icon aria-hidden=true><li><a href="https://www.linkedin.com/in/annapbarnes/?originalSubdomain=uk" target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=M8KOhXQAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://www.kcl.ac.uk/people/anna-barnes target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/emine-yilmaz/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/emine-yilmaz/avatar_hu849ce1ea1b0f0df4920e8c899f679c30_10050_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/emine-yilmaz/>Emine Yilmaz</a></h2><h3>Advisory Board Member of the UK Open Multimodal AI Network, Professor and ELLIS Fellow at University College London, and Amazon Scholar</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/emine-yilmaz-978b937/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.com/citations?user=ocmAN4YAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://sites.google.com/site/emineyilmaz/ target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/maria-luciana-axente/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/maria-luciana-axente/avatar_hu910f48fbd25fdcdf40b3170be8c1efd9_242277_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/maria-luciana-axente/>Maria Luciana Axente</a></h2><h3>Advisory Board Member of the UK Open Multimodal AI Network, Founder and CEO of Responsible Intelligence, and former Head of AI Public Policy and Ethics at PwC UK</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/mariaaxente/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href=https://responsibleintelligence.co.uk/ target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/rebecca-croasdale-wood/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/rebecca-croasdale-wood/avatar_hud31e21cd93b98bc0c32a4c748f54a6a2_493092_270x270_fill_lanczos_center_3.png alt=Avatar></a><div class=portrait-title><h2><a href=/author/rebecca-croasdale-wood/>Rebecca Croasdale-Wood</a></h2><h3>Senior Director of Augmented Biologics Design and Global MLAB Lead at AstraZeneca</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/rebecca-croasdale-wood-95874688/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.co.uk/citations?user=EopQoZgAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/ronghui-liu/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/ronghui-liu/avatar_hu8a33ac97b6eedcbef0c7279e34a859a1_139799_270x270_fill_lanczos_center_3.png alt=Avatar></a><div class=portrait-title><h2><a href=/author/ronghui-liu/>Ronghui Liu</a></h2><h3>Professor of Networks and Transport Operations at University of Leeds</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/prof-ronghui-liu-98745326/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.com/citations?user=lZNeTSwAAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://environment.leeds.ac.uk/transport/staff/951/professor-ronghui-liu target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/thomas-gorochowski/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/thomas-gorochowski/avatar_hu7c38fa4f4d295784d4c55ff52fd651c7_68909_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/thomas-gorochowski/>Thomas Gorochowski</a></h2><h3>Professor of Biological Engineering at University of Bristol</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/tgorochowski/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.com/citations?user=q18IlDoAAAAJ&amp;hl=enhu" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://biocomputelab.github.io/team/thomas-gorochowski/ target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/tian-xie/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/tian-xie/avatar_hub9593d566e5e968acfa37fffb10f3d99_31830_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/tian-xie/>Tian Xie</a></h2><h3>Principal Research Manager and Project Lead at Microsoft Research AI for Science</h3><ul class=network-icon aria-hidden=true><li><a href=https://www.linkedin.com/in/txie-93/ target=_blank rel=noopener><i class="fab fa-linkedin"></i></a></li><li><a href="https://scholar.google.com/citations?user=xFbOAf8AAAAJ&amp;hl=en" target=_blank rel=noopener><i class="ai ai-google-scholar"></i></a></li><li><a href=https://txie.me/ target=_blank rel=noopener><i class="fas fa-globe"></i></a></li></ul></div></div></div></div></section><section id=welcome_address class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Welcome Address</h1></div><div class=col-md-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/aimie-chapple/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/aimie-chapple/avatar_hu96cb49028180967075efdf16dcbc297e_30029_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/aimie-chapple/>Aimie Chapple</a></h2><h3>Vice President Operations at University College London</h3></div></div></div></div></section><section id=pre-events class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Pre-workshop</h1><p>15 Sep 2025<br>Torrington Place (1-19), London, WC1E 7HB</p></div><div class=col-md-12><center><table><thead><tr><th>Time</th><th>    Event</th></tr></thead><tbody><tr><td>13:00 – 17:00</td><td>    Mini-hackathon</td></tr><tr><td>13:00 – 17:00</td><td>    Early registration (access required)</td></tr></tbody></table></center></div></div></div></section><section id=programme class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Preliminary Programme (In Person Only)</h1></div><div class=col-md-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div><center><p style=font-size:24px;border:none;font-weight:700;margin-bottom:4px>Workshop Day 1: 16 Sep 2025</p><p style=font-size:22px;font-weight:400;color:rgba(0,0,0,.54)>Barbican Centre, London, EC2Y 8DS</p><table><thead><tr><th>Time</th><th>    Event</th></tr></thead><tbody><tr><td>08:30 – 09:00</td><td>    Registration, coffee/tea, and biscuits</td></tr><tr><td>09:00 – 09:10</td><td>    Welcome address: Aimie Chapple, Vice-President, University College London</td></tr><tr><td>09:10 – 09:30</td><td>    Opening talk: Haiping Lu, Director, UK Open Multimodal AI Network</td></tr><tr><td>09:30 – 10:10</td><td>    <strong>Keynote 1</strong>: Tian Xie, Principal Research Manager, Microsoft Research AI4Science</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> Accelerating materials design with AI emulators and generators<br><strong>Abstract:</strong> The design of novel materials has been a cornerstone of technological progress, driving transformative innovations such as the adoption of electric vehicles, the development of highly efficient solar cells, and the widespread use of superconductors in magnetic resonance imaging (MRI) systems. At Microsoft Research, we develop two foundational artificial intelligence (AI) models to accelerate the materials discovery process. The first model, MatterGen, is an AI generator that proposes novel materials candidates given prompts of required properties. The second model, MatterSim, is an AI emulator that then simulates the properties of the generated candidates for the target application. The two models work together as a flywheel to drive the discovery of novel materials for broad applications. This presentation will provide a comprehensive overview of the architecture MatterSim and MatterGen, as well as how they can be used to deliver real-world impact in materials design.</td></td><td></td></tr><tr><td>10:10 – 10:45</td><td>    Community talks 1</td></tr><tr><td>10:45 – 11:00</td><td>    Group photos</td></tr><tr><td>11:00 – 11:30</td><td>    Coffee/tea, biscuits, and posters</td></tr><tr><td>11:30 – 12:10</td><td>    <strong>Keynote 2</strong>: Maria Luciana Axente, CEO, Responsible Intelligence</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> Beyond single-track thinking: governing the ethical complexity of multimodal AI<br><strong>Abstract:</strong> Given the emergence of these unique AI systems, our current governance frameworks must evolve, addressing the urgent ethical dilemmas they raise and enabling a robust, proportionate risk management approach tailored to their complexity and requirements.</td></td><td></td></tr><tr><td>12:10 – 12:40</td><td>    Community talks 2</td></tr><tr><td>12:40 – 13:50</td><td>    Lunch and posters</td></tr><tr><td>13:50 – 14:30</td><td>    <strong>Keynote 3</strong>: Rebecca Croasdale-Wood, Senior Director, Global MLAB Lead, AstraZeneca</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> Integrating AI into biologics discovery workflows<br><strong>Abstract:</strong> —</td></td><td></td></tr><tr><td>14:30 – 15:00</td><td>    Community talks 3</td></tr><tr><td>15:00 – 15:30</td><td>    Coffee/tea, biscuits, and posters</td></tr><tr><td>15:30 – 16:10</td><td>    <strong>Keynote 4</strong>: Thomas Gorochowski, Professor of Biological Engineering, University of Bristol</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> Data-centric approaches to biological design and engineering<br><strong>Abstract:</strong> High-throughput multi-modal experiments are revolutionising our understanding of biological complexity and offer a rich foundation on which to establish data-centric and mechanistic models of living cells. In this talk, I will present some of the sequencing methodologies my group has been developing to aid in the reprogramming of cells, providing broad and detailed information about diverse cellular processes and some of the insights this type of data has provided. I will also discuss some of the major challenges associated with the design of these experiments, showing how simulation can help; the chlleneges of working with heterogeneous data for biological design; and our efforts to to improve data interoperability and safety across the field of engineering biology.</td></td><td></td></tr><tr><td>16:10 – 17:00</td><td>    Conducting impactful research (panel discussion 1)</td></tr><tr><td>17:00 – 17:30</td><td>    Exploring barbican</td></tr><tr><td>17:30 – 20:30</td><td>    Networking reception</td></tr></tbody></table></center><center><p style=font-size:24px;border:none;font-weight:700;margin-bottom:4px>Workshop Day 2: 17 Sep 2025</p><p style=font-size:22px;font-weight:400;color:rgba(0,0,0,.54)>Barbican Centre, London, EC2Y 8DS</p><table><thead><tr><th>Time</th><th>    Event</th></tr></thead><tbody><tr><td>08:30 – 09:00</td><td>    Registration, coffee/tea, and biscuits</td></tr><tr><td>09:00 – 09:20</td><td>    Invited talk: EPSRC and Tomorrow&rsquo;s Engineering Research Challenges, Simon Crook</td></tr><tr><td>09:20 – 09:40</td><td>    Open Multimodal AI Benchmark (OMAIB)</td></tr><tr><td>09:40 – 10:20</td><td>    <strong>Keynote 5</strong>: Anna Barnes, Director of the King’s Technology Evaluation Centre, King’s College London</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> AI in health and care — helping developers to think more critically about deployment, integration, and evidence generation<br><strong>Abstract:</strong> King’s College Technology Evaluation Centre (KiTEC) was commissioned by NHS England in 2020 to support the evaluation of AI tools for healthcare service provision. This talk provides an overview of the methodology, a description of the evaluation criteria in terms of clinical and economic effectiveness and the lessons learned during the evaluation process.</td></td><td></td></tr><tr><td>10:20 – 10:50</td><td>    Community talks 4</td></tr><tr><td>10:50 – 11:20</td><td>    Coffee/tea, biscuits, and posters</td></tr><tr><td>11:20 – 12:00</td><td>    <strong>Keynote 6</strong>: Ronghui Liu, Professor of Networks and Transport Operations, University of Leeds</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> Smart mobility: AI and data science powering the future of multimodal transport<br><strong>Abstract:</strong> This presentation explores how artificial intelligence and data science are reshaping multimodal transport systems - including public transport, ridesharing, cycling, andwalking – into more intelligent, efficient, and equitable forms of mobility.By leveraging diverse data sources—such as GPS trajectories, sensors, video andmobile applications—AI enables the analysis and inference of travel patterns and user needs across socio-economic groups, while also supporting real-time decision-making, route optimisation, and predictive maintenance of transport infrastructure. Cloud-computing provides the architecture for scalable solutions, including digital twins for infrastructure monitoring and reinforcement learning for dynamic scheduling. Case studies are presented to illustrate how these technologies can address challenges like congestion, system upkeep, and last-mile connectivity. The talk concludes with a call for cross-sector collaboration among academia, industry, and public agencies, to advance inclusive and sustainable mobility through continued innovation in AI and data science.</td></td><td></td></tr><tr><td>12:00 – 12:30</td><td>    Community talks 5</td></tr><tr><td>12:30 – 13:40</td><td>    Lunch and posters</td></tr><tr><td>13:40 – 14:20</td><td>    <strong>Keynote 7</strong>: Ampea Karikari-Boateng, Principal R&amp;D Engineer, Offshore Renewable Energy Catapult</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> AI-renewed: transforming offshore renewables with multimodal intelligence<br><strong>Abstract:</strong> The offshore renewable energy industry is entering a new era where artificial intelligence (AI) is not just a tool, but a transformative force across the entire lifecycle of renewable energy assets. From enhancing device design, accelerating consenting of new developments, to streamlining operations and maintenance, AI is reshaping how we plan, operate, and advance offshore infrastructure. Here, we explore how AI has impacted wind energy by tracking its evolution from unimodal machine learning models, used in condition monitoring and document intelligence, to the emerging frontier of multimodal AI. These next-generation systems aim to extract deeper insights by combining diverse data sources such as sensor streams, geospatial imagery, and operational documentation. Through real-world examples and visionary use cases, we’ll uncover how multimodal AI is helping accelerate environmental monitoring to achieve faster regulatory approvals, enhance predictive maintenance and autonomous inspection, and enable holistic lifecycle planning and circularity in offshore assets.</td></td><td></td></tr><tr><td>14:20 – 14:30</td><td>    Invited talk: Multimodal AI for solar forecasting and future grid balance, Yupeng Wu</td></tr><tr><td>14:30 – 15:00</td><td>    Learning from experience: career reflections (panel discussion 2)</td></tr><tr><td>15:00 – 15:30</td><td>    Coffee/tea, biscuits, and posters</td></tr><tr><td>15:30 – 16:10</td><td>    <strong>Keynote 8</strong>: Emine Yilmaz, Professor and ELLIS Fellow, University College London</td></tr><tr><td><td style=word-wrap:break-word;max-width:810px;text-align:justify;padding-left:1.3em;text-indent:-1.3em>    <strong>Title:</strong> Using large language models for evaluation: opportunities and limitations<br><strong>Abstract:</strong> Large Language Models (LLMs) have shown significant promise as tools for automated evaluation across diverse domains. While using LLMs for evaluation come with significant advantages potentially alleviating the reliance on costly and subjective human assessments, the adoption of LLM-based evaluation is not without challenges. In this talk we discuss about the transformative potential and the inherent constraints of using LLMs for evaluation tasks. In particular, we describe some of the challenges that come with LLM-based evaluation, such as biases and variability in judgment. We further discuss how LLMs can augment traditional evaluation practices while acknowledging the need for cautious and informed integration.</td></td><td></td></tr><tr><td>16:10 – 16:25</td><td>    Prize winner announcement</td></tr><tr><td>16:25 – 16:30</td><td>    Next steps of UKOMAIN</td></tr></tbody></table></center></div></div></div></section><section id=key_dates class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Key Dates and Deadlines</h1></div><div class=col-md-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div><center><table><thead><tr><th></th><th>Open Date       </th><th>Close Date       </th></tr></thead><tbody><tr><td>Call for Abstracts       </td><td>Wed, 30th April       </td><td>Tue, 5th August</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Abstract Acceptance Notification       </td><td>–</td><td>Tue, 12th August</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Final Abstract Submission       </td><td>–</td><td>Mon, 8th September (5 PM)</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Registration Open       </td><td>Tue, 27th May       </td><td>Closes when full or Sun, 7th September (11 PM)</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Cancellation Deadline (with refund)       </td><td>–</td><td>Fri, 5th September</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Call for Volunteers       </td><td>Tue, 27th May       </td><td>Tue, 26th August</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Volunteer Acceptance Notification       </td><td>–</td><td>Fri, 29th August</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Travel Bursary for Inclusive Participation       </td><td>Tue, 27th May       </td><td>Tue, 26th August</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Travel Bursary Decision Notification       </td><td>–</td><td>Fri, 29th August</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Call for Sponsors       </td><td>Wed, 7th May       </td><td>Tue, 2nd September</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Photo Competition Submission       </td><td>Mon, 18th August       </td><td>Tue, 16th September</td></tr><tr><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td><td><div style=line-height:.4>​</div></td></tr><tr><td>Photo Competition Winners Announced       </td><td>–</td><td>Wed, 17th September</td></tr></tbody></table></center></div></div></div></section><section id=organiser class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Organising Committee</h1></div><div class="col-12 col-sm-auto people-person"><a href=/author/haiping-lu/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/haiping-lu/avatar_hucb84e28ca1e19b7e1577e26fab350297_1984751_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/haiping-lu/>Haiping Lu</a></h2><h3>Director of the UK Open Multimodal AI Network, Professor of Machine Learning & Head of AI Research Engineering, University of Sheffield</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/nicola-morley/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/nicola-morley/avatar_huee12ce122072ef7a2494e5e3ffca47ad_107821_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/nicola-morley/>Nicola Morley</a></h2><h3>Deputy Director of the UK Open Multimodal AI Network & Professor of Materials Physics</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/peter-charlton/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/peter-charlton/avatar_hu9832f0fbf47147de4197ece20ae3646f_88560_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/peter-charlton/>Peter Charlton</a></h2><h3>Lead for Early Career Researchers at the UK Open Multimodal AI Network & Senior Research Scientist, Nokia Bell Labs</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/nataliya-tkachenko/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/nataliya-tkachenko/avatar_hud305836d2c327d7a6e62f9dc732663c7_174213_270x270_fill_lanczos_center_3.png alt=Avatar></a><div class=portrait-title><h2><a href=/author/nataliya-tkachenko/>Nataliya Tkachenko</a></h2><h3>Lead for Industry & Public Engagement at the UK Open Multimodal AI Network & Generative AI Ethics & Assurance Lead, Lloyds Banking Group</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/yao-zhang/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/yao-zhang/avatar_hu760cf5d088f804cab9d4debed805aea6_115572_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/yao-zhang/>Yao Zhang</a></h2><h3>Lead for Equality, Diversity, and Inclusion at the UK Open Multimodal AI Network & Lecturer in Marine/Maritime Digitalisation and Automation, UCL</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/dezong-zhao/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/dezong-zhao/avatar_hu04433db6323f73143f4b0cba43078db5_161464_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/dezong-zhao/>Dezong Zhao</a></h2><h3>Lead for UKRI and Government at the UK Open Multimodal AI Network & Reader in Autonomous Systems, The University of Glasgow</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/aayush-chiniwalla/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/aayush-chiniwalla/avatar_hud9bec5c3b9e254cec1f0214534e9afa9_163681_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/aayush-chiniwalla/>Aayush Chiniwalla</a></h2><h3>Network Coordinator of the UK Open Multimodal AI Network</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/shuo-zhou/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/shuo-zhou/avatar_hu22b99ecafd4f38ffa0d6bc65fe86db49_47530_270x270_fill_q75_h2_lanczos_center_2.webp alt=Avatar></a><div class=portrait-title><h2><a href=/author/shuo-zhou/>Shuo Zhou</a></h2><h3>Lecturer in Machine Learning & Deputy Head of AI Research Engineering, University of Sheffield</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/xianyuan-liu/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/xianyuan-liu/avatar_hu42e6bb4f77b4f8df2d26e0165d9cae14_23239_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/xianyuan-liu/>Xianyuan Liu</a></h2><h3>Senior AI Research Engineer & Assistant Head of AI Research Engineering, University of Sheffield</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/zhixiang-chen/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/zhixiang-chen/avatar_hu53d97f702b54cce4719f707188b70a95_45534_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/zhixiang-chen/>Zhixiang Chen</a></h2><h3>Lecturer in Machine Learning</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/sina-tabakhi/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/sina-tabakhi/avatar_hu2d09f6770ebfe31111cf5b827920c602_48516_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/sina-tabakhi/>Sina Tabakhi</a></h2><h3>PhD Candidate in Machine Learning, School of Computer Science, University of Sheffield</h3></div></div></div></div></section><section id=technical class="home-section wg-people"><div class=home-section-bg></div><div class=container><div class="row justify-content-center people-widget"><div class="col-md-12 section-heading"><h1>Technical Support</h1></div><div class="col-12 col-sm-auto people-person"><a href=/author/lalu-muhammad-riza-rizky/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/lalu-muhammad-riza-rizky/avatar_hu65938eafaa9229e89cc28976d700235a_6128244_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/lalu-muhammad-riza-rizky/>Lalu Muhammad Riza Rizky</a></h2><h3>AI Research Engineer</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/mohammod-suvon/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/mohammod-suvon/avatar_huf7be7f6950729f5661dac3da9684d920_115281_270x270_fill_q75_lanczos_center.jpg alt=Avatar></a><div class=portrait-title><h2><a href=/author/mohammod-suvon/>Mohammod Suvon</a></h2><h3>AI Research Engineer</h3></div></div><div class="col-12 col-sm-auto people-person"><a href=/author/wenrui-fan/><img width=270 height=270 loading=lazy class="avatar avatar-circle" src=/author/wenrui-fan/avatar_hu71c0b713ccb1e4368f6fc7683823f2b9_729844_270x270_fill_lanczos_center_3.png alt=Avatar></a><div class=portrait-title><h2><a href=/author/wenrui-fan/>Wenrui Fan</a></h2><h3>AI Research Engineer</h3></div></div></div></div></section><section id=partners class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Partners</h1></div><div class=col-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div><div style=text-align:center><img src=/media/uos_logo.png alt="CMI Logo" style=width:270px;height:auto;display:inline-block;margin-right:20px>
<img src=/media/UCL_logo.jpg alt="ATI Logo" style=width:230px;height:auto;display:inline-block;margin-right:20px>
<img src=/media/UoG_logo.jpg alt="ATI Logo" style=width:250px;height:85px;display:inline-block;margin-right:20px>
<img src=/media/ati_logo.jpg alt="ATI Logo" style=width:205px;height:auto;display:inline-block;margin-right:20px></div></div></div></div></section><section id=sponsors class="home-section wg-blank"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Our Key Sponsors</h1></div><div class=col-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div><div style=text-align:center><img src=/media/ukri_epsr_council_logo.jpg style=width:420px;height:auto;display:inline-block;margin-right:20px>
<img src=/media/henry_royce_institute_logo.png style=width:420px;height:auto;display:inline-block;margin-right:20px></div></div></div></div></section><section id=contact class="home-section wg-contact"><div class=home-section-bg></div><div class=container><div class="row justify-content-center"><div class="section-heading col-12 mb-3 text-center"><h1 class=mb-0>Contact Us</h1></div><div class=col-12><style>.sticky-buttons{position:fixed;top:6px!important;left:50%;transform:translateX(-50%);background:rgba(255,255,255,.9);padding:5px 8px;border-radius:8px;box-shadow:0 4px 6px rgba(0,0,0,.1);z-index:9999;display:flex;flex-direction:row;flex-wrap:nowrap;overflow-x:auto;max-width:100vw}.sticky-buttons button{font-family:open sans,Arial,sans-serif;font-size:14px;font-weight:700;padding:4px 12px;border:none;border-radius:4px;background-color:#154c79;color:#abdbe3;cursor:pointer;margin-right:8px;flex:none;min-width:120px;white-space:nowrap}</style><div class=sticky-buttons><a href=#speaker style=text-decoration:none><button>Speakers</button>
</a><a href=/call-for-sponsorship/ style=text-decoration:none><button>Sponsor Us</button>
</a><a href=#programme style=text-decoration:none><button>Programme</button>
</a><a href=#about style=text-decoration:none><button>About</button>
</a><a href=#contact style=text-decoration:none><button>Contact Us</button></a></div><p><i class="fas fa-envelope fa-2x" style=margin-right:20px></i> Email the organisers: <a href=mailto:ukomain-mmai25@googlegroups.com><a href=mailto:ukomain-mmai25@googlegroups.com>ukomain-mmai25@googlegroups.com</a></a></p><ul class=fa-ul><li><i class="fa-li fas fa-map-marker fa-2x" aria-hidden=true></i>
<span id=person-address>Frobisher Auditorium 1, Level 4, Barbican Centre, Silk Street, Barbican, London, EC2Y 8DS</span></li></ul><div class=d-none><input id=map-provider value=mapnik>
<input id=map-lat value=51.520222>
<input id=map-lng value=-0.093789>
<input id=map-dir value="Frobisher Auditorium 1, Level 4, Barbican Centre, Silk Street, Barbican, London, EC2Y 8DS">
<input id=map-zoom value=15>
<input id=map-api-key value></div><div id=map></div></div></div></div></section></div><div class=page-footer><div class=container><footer class=site-footer><p class="powered-by copyright-license-text">© 2025 UK Open Multimodal AI Network (UKOMAIN).<br><a href=/privacy-and-data-use/>Privacy and Data Use Notice</a></p><p class=powered-by>Published with <a href="https://wowchemy.com/?utm_campaign=poweredby" target=_blank rel=noopener>Wowchemy</a> — the free, <a href=https://github.com/wowchemy/wowchemy-hugo-themes target=_blank rel=noopener>open source</a> website builder that empowers creators.</p></footer></div></div><script src=/js/vendor-bundle.min.b4708d4364577c16ab7001b265a063a4.js></script><script src=https://cdn.jsdelivr.net/npm/leaflet@1.7.1/dist/leaflet.min.js integrity crossorigin=anonymous></script><script id=search-hit-fuse-template type=text/x-template>
    <div class="search-hit" id="summary-{{key}}">
      <div class="search-hit-content">
        <div class="search-hit-name">
          <a href="{{relpermalink}}">{{title}}</a>
          <div class="article-metadata search-hit-type">{{type}}</div>
          <p class="search-hit-description">{{snippet}}</p>
        </div>
      </div>
    </div>
  </script><script src=https://cdn.jsdelivr.net/gh/krisk/Fuse@v3.2.1/dist/fuse.min.js integrity="sha512-o38bmzBGX+hD3JHWUFCDA09btWaqrNmoJ3RXLlrysA7PP01Kgs4UlE4MhelE1v5dJR3+cxlR4qQlotsW7jKsnw==" crossorigin=anonymous></script><script src=https://cdn.jsdelivr.net/gh/julmot/mark.js@8.11.1/dist/jquery.mark.min.js integrity="sha512-mhbv5DqBMgrWL+32MmsDOt/OAvqr/cHimk6B8y/bx/xS88MVkYGPiVv2ixKVrkywF2qHplNRUvFsAHUdxZ3Krg==" crossorigin=anonymous></script><script id=page-data type=application/json>{"use_headroom":true}</script><script src=/js/wowchemy-headroom.db4755770454eb63685f8de785c0a172.js type=module></script><script src=/en/js/wowchemy.min.6ab16275cbca742a586c1726e3d94093.js></script><script src=/js/wowchemy-map.a26e9d2f7238ba5b868384f1c5bc6477.js type=module></script></body></html>